{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of python_live_session_template.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Ijg5wUCTQYG"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/datacamp/python-live-training-template/blob/master/assets/datacamp.svg?raw=True\" alt = \"DataCamp icon\" width=\"50%\">\n",
        "</p>\n",
        "<br><br>\n",
        "\n",
        "\n",
        "## **Applied Machine Learning - Ensemble Modeling Live Training**\n",
        "\n",
        "Welcome to this hands-on training where you will immerse yourself in applied machine learning in Python where we'll explore model stacking. Using `sklearn.ensemble`, we'll learn how to create layers that are stacking-ready.\n",
        "\n",
        "The foundations of model stacking:\n",
        "\n",
        "* Create various types of baseline models, including linear and logistic regression using Scikit-Learn, for comparison to ensemble methods.\n",
        "* Build layers, then stack them up.\n",
        "* Calculate and visualize performance metrics.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## **1st Dataset**\n",
        "\n",
        "\n",
        "The first dataset we'll use is a CSV file named `pima-indians-diabetes.csv`, which contains data on females of Pima Indian heritage that are at least 21 years old. It contains the following columns:\n",
        "\n",
        "- `n_preg`: Number of pregnancies\n",
        "- `pl_glucose`: Plasma glucose concentration 2 hours after an oral glucose tolerance test\n",
        "- `dia_bp`: Diastolic blood pressure (mm Hg)\n",
        "- `tri_thick`: Triceps skin fold thickness (mm)\n",
        "- `serum_ins`: 2-Hour serum insulin (mu U/ml)\n",
        "- `bmi`: Body mass index (weight in kg/(height in m)^2)\n",
        "- `diab_ped`: Diabetes pedigree function\n",
        "- `age`: Age (years)\n",
        "- `class`: Class variable (0 or 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EMQfyC7GUNhT",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8t_EwRNZPLB",
        "colab": {}
      },
      "source": [
        "# Read in the dataset as Pandas DataFrame\n",
        "diabetes = pd.read_csv('https://github.com/datacamp/Applied-Machine-Learning-Ensemble-Modeling-live-training/blob/master/data/pima-indians-diabetes.csv?raw=true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRJPuinPZpGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at data using the info() function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6OVOkU80oKP",
        "colab_type": "text"
      },
      "source": [
        "## **Observations:** \n",
        "- The `info()` function is critical to beginning to understand your data.  Here, there are no missing values.  However, that is not typical.\n",
        "- There is a mixture of integers and floats with the first 5 columns being `int64`, the next 2 `float64` and the last 2 'int64`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3hAsYrhVi4L",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Q&A\n",
        "\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6UtlpG_Zo50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at data using the describe() function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCK9W_gk1HG8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Observations:** \n",
        "- The `.describe()` function gives the summary statistics of the data.  Notice that the min of the 1st six columns is zero.  Even though there are no missing values, this is indicative of the measurements for those features having not been captured.\n",
        "- Although we previously saw there is a mixture of integer and float data types (as seen with `.info()`), the printout makes it appear as if all values are float.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE5F_JUQ2X-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the first 5 rows of the data using the head() function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2VCIx0K2bT1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## **Observation:**\n",
        "- Printing out the first 5 rows, we see that the data types of the columns are indeed as stated previously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajAzhMDc2b1D",
        "colab_type": "text"
      },
      "source": [
        "## Let's check the number in each class:\n",
        "\n",
        "This avoids getting surprised by great results that are actually a side effect of class imbalance.  This happens when the majority class far outweighs the minority class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKeXN3441-9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Summarize class distribution\n",
        "target = diabetes['class']\n",
        "counter = Counter(target)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOpbGyQw55v3",
        "colab_type": "text"
      },
      "source": [
        "## **Observation:** For every two negative cases there is one positive case, not enough of a difference to be considered class imbalance.  \n",
        "- Class imbalance tends to exist when the majority class is > 90% although there is no hard and fast rule about this threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5XaYl9ZZ8B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert Pandas DataFrame to numpy array - Return only the values of the DataFrame with DataFrame.to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlGa9IBc7Gsr",
        "colab_type": "text"
      },
      "source": [
        "### Always verify that your X matrix and target array have the same number of rows to avoid errors during model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FEvD6Ab6InP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create X matrix and y (target) array using slicing [row_start:row_end, col_start:target_col],[row_start:row_end, target_col]\n",
        "\n",
        "\n",
        "# Print X matrix and y (target) array dimensions using .shape \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoI7t4U-Z8LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert X matrix data types to 'float32' for consistency using .astype()\n",
        "\n",
        "\n",
        "# Convert y (target) array to 'str' using .astype()\n",
        "\n",
        "\n",
        "# Encode class labels in y array using dot notation with LabelEncoder().fit_transform()\n",
        "# Hint: y goes in the fit_transform function call\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djXWv2xp9v1q",
        "colab_type": "text"
      },
      "source": [
        "### Don't let the `.astype('str')` throw you!  This is simply taking the class labels and label encoding them â€“ regardless of their original format.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHHu8uz7_yVa",
        "colab_type": "text"
      },
      "source": [
        "## **Creating a Naive Classifier**\n",
        "Here we'll use the `DummyClassifier` from `sklearn`.  This creates a so-called 'naive' classifer and is simply a model that predicts a single class for all of the rows, regardless of their original class.  \n",
        "\n",
        "1. `DummyClassifier()` arguments:\n",
        " - `strategy`: Strategy to use to generate predictions.\n",
        "\n",
        "2. `RepeatedStratifiedKFold()` arguments:\n",
        " - `n_splits`: Number of folds.\n",
        " - `n_repeats`: Number of times cross-validator needs to be repeated.\n",
        " - `random_state`: Controls the generation of the random states for each repetition. Pass an int for reproducible output across multiple function calls.  (This is an equivalent argument to np.random.seed above, but will be specific to this naive model.)\n",
        "\n",
        "3. `cross_val_score()` arguments:\n",
        " - The model to use.\n",
        " - The data to fit. (X)\n",
        " - The target variable to try to predict. (y)\n",
        " - `scoring`: A single string scorer callable object/function such as 'accuracy' or 'roc_auc'.  See https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for more options.\n",
        " - `cv`: Cross-validation splitting strategy (default is 5)\n",
        " - `n_jobs`: Number of CPU cores used when parallelizing.  Set to -1 helps to avoid non-convergence errors.\n",
        " - `error_score`: Value to assign to the score if an error occurs in estimator fitting. If set to â€˜raiseâ€™, the error is raised. If a numeric value is given, FitFailedWarning is raised."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL4huFGPZ8RA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate naive\n",
        "\n",
        "# Instantiate a DummyClassifier with 'most_frequent' strategy\n",
        "naive = \n",
        "\n",
        "# Create RepeatedStratifiedKFold cross-validator with 10 folds, 3 repeats and a seed of 1.\n",
        "cv = \n",
        "\n",
        "# Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'accuracy' scoring, cross validator, n_jobs=-1, and error_score set to 'raise'\n",
        "n_scores = \n",
        "\n",
        "# Print mean and standard deviation of n_scores: \n",
        "print('Naive score: %.3f (%.3f)' % (mean(), std()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tEgwsOfsoB6",
        "colab_type": "text"
      },
      "source": [
        "## **Observation** \n",
        "- We want to do better than 65% accuracy to consider any other models as an improvement to a totally naive model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8QZOyg8s1eQ",
        "colab_type": "text"
      },
      "source": [
        "## **Creating a Baseline Classifier**\n",
        "Now we'll create a baseline classifier, one that seeks to correctly predict the class that each observation belongs to.  Since the target variable is binary, we'll instantiate a `DecisionTreeClassifier` model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QczFUGSfbQvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate baseline model\n",
        "\n",
        "# Instantiate a DecisionTreeClassifier\n",
        "model = \n",
        "\n",
        "# Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'accuracy' scoring, cross validator 'cv', and error_score set to 'raise'\n",
        "m_scores = \n",
        "\n",
        "# Print mean and standard deviation of m_scores: \n",
        "print('Baseline score: %.3f (%.3f)' % (mean(), std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRUBiqqmtNA6",
        "colab_type": "text"
      },
      "source": [
        "## **Observation**\n",
        "- We want to do better than 70% with a Stacking Classifier to consider it an improvement over this baseline Decision Tree model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BMYfcKeDY85K"
      },
      "source": [
        "## **Getting started with Stacking Classifier**\n",
        "\n",
        "- We're going to compare several additional baseline classifiers to see if they perform better than the Decision Tree Classifier we just trained previously.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2pwEXnQBEFf",
        "colab_type": "text"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/datacamp/Applied-Machine-Learning-Ensemble-Modeling-live-training/blob/master/assets/stacking.png?raw=True\" alt = \"Stacking\" width=\"90%\">\n",
        "</p>\n",
        "<br><br>\n",
        "\n",
        "- We'll start by importing additional packages that we'll need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHCHmx7k5NeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import several other classifiers for ensemble\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teQMB0aWxhcN",
        "colab_type": "text"
      },
      "source": [
        "## Create custom functions\n",
        "1. get_stacking() - This function will create the layers of our `StackingClassifier()`.\n",
        "2. get_models() - This function will create a dictionary of models to be evaluated.\n",
        "3. evaluate_model() - This function will evaluate each of the models to be compared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtHxQFPvMqu",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 1: get_stacking()\n",
        "1. `StackingClassifier()` arguments:\n",
        " - `estimators`: List of baseline classifiers\n",
        " - `final_estimator`: Defined meta classifier \n",
        " - `cv`: Number of cross validations to perform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFhBv6jR6FOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_stacking():\n",
        "def :\n",
        "\n",
        "\t# Create an empty list for the base models called layer1\n",
        "  \n",
        "\n",
        "  # Append tuple with classifier name and instantiations (no arguments) for KNeighborsClassifier, SVC, and GaussianNB base models\n",
        "  # Hint: layer1.append(('ModelName', Classifier()))\n",
        "  \n",
        "\n",
        "  # Instantiate Logistic Regression as meta learner model called layer2\n",
        "  \n",
        "\n",
        "\t# Define StackingClassifier() called model passing layer1 model list and meta learner with 5 cross-validations\n",
        "  \n",
        "\n",
        "  # return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5szw9liyaxp",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 2: get_models()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hEJlDLB4kv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_models():\n",
        "def :\n",
        "\n",
        "  # Create empty dictionary called models\n",
        "  \n",
        "\n",
        "  # Add key:value pairs to dictionary with key as ModelName and value as instantiations (no arguments) for KNeighborsClassifier, SVC, and GaussianNB base models\n",
        "  # Hint: models['ModelName'] = Classifier()\n",
        " \n",
        "\n",
        "  # Add key:value pair to dictionary with key called Stacking and value that calls get_stacking() custom function\n",
        "  \n",
        "\n",
        "  # return dictionary\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flSG4dH1zCTK",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 3: evaluate_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGLKRr0j5Nit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define evaluate_model:\n",
        "def :\n",
        "\n",
        "  # Create RepeatedStratifiedKFold cross-validator with 10 folds, 3 repeats and a seed of 42.\n",
        "  cv = \n",
        "\n",
        "  # Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'accuracy' scoring, cross validator 'cv', n_jobs=-1, and error_score set to 'raise'\n",
        "  scores = \n",
        "\n",
        "  # return scores\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5wmC-TH7B7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign get_models() to a variable called models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02tyK34l2eh7",
        "colab_type": "text"
      },
      "source": [
        "## Python Dictionary Review:\n",
        "- The items() method is used to return the list with all dictionary keys with values. Parameters: This method takes no parameters. Returns: A view object that displays a list of a given dictionary's (key, value) tuple pair.\n",
        "- For our purposes, we'll use the dictionary created when we call the get_models() custom function in a for loop to iterate over each key:value pair and store the results.\n",
        "- Then, we will plot the results as a `boxplot` for comparison using `seaborn`.\n",
        "\n",
        "1. `sns.boxplot()` arguments:\n",
        " - `x`: Names of the variables in the data\n",
        " - `y`: Names of the variables in the data\n",
        " - `showmeans`: Whether or not to show mark at the mean of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzXmYt1o6FWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the models and store results\n",
        "# Create an empty list for the results\n",
        "results =\n",
        "\n",
        "# Create an empty list for the model names\n",
        "names = \n",
        "\n",
        "# Create a for loop that iterates over each name, model in models dictionary \n",
        "for :\n",
        "\n",
        "\t# Call evaluate_model(model) and assign it to variable called scores\n",
        "\t\n",
        " \n",
        "  # Append output from scores to the results list\n",
        "\t\n",
        " \n",
        "  # Append name to the names list\n",
        "\t\n",
        " \n",
        "  # Print name, mean and standard deviation of scores:\n",
        "\tprint('>%s %.3f (%.3f)' % (, mean(), std()))\n",
        " \n",
        "# Plot model performance for comparison using names for x and results for y and setting showmeans to True\n",
        "sns.boxplot(x=, y=, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUqeWsol5RAt",
        "colab_type": "text"
      },
      "source": [
        "## **Observation**\n",
        "- Recall that we want to do better than 70% with a Stacking Classifier to consider it an improvement over the Decision Tree baseline model and, although we did achieve that, we can probably do even better with this dataset.  \n",
        "- Let's try some hyperparameter tuning via cross-validation next..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwc_6_Qf4amu",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Q&A\n",
        "\n",
        "--- \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMZ8gTb6LGCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import additional libraries\n",
        "from xgboost import XGBClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import xgboost as xgb\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfctBvrs4ZcQ",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 4: best_model(name, model)\n",
        "- We're going to create a Pipeline that scales the data before applying the parameter grid via cross-validation.\n",
        "- Then it returns the model with the best hyperparameters from the search grid for each model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RG7lpMY3Bzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define best_model:\n",
        "def best_model(name, model):\n",
        "  pipe = Pipeline([('scaler', StandardScaler()), ('classifier',model)])  \n",
        "\n",
        "  if name == 'SVM':\n",
        "    param_grid = {'classifier__kernel' : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']} \n",
        "    # Create grid search object\n",
        "    # this uses k-fold cv\n",
        "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs=-1)\n",
        "\n",
        "    # Fit on data\n",
        "    best_clf = clf.fit(X, y)\n",
        "\n",
        "    best_hyperparams = best_clf.best_estimator_.get_params()['classifier']\n",
        "\n",
        "    return name, best_hyperparams \n",
        "\n",
        "  if name == 'Bayes': \n",
        "    param_grid = {'classifier__var_smoothing' : np.array([1e-09, 1e-08])} \n",
        "    # Create grid search object\n",
        "    # this uses k-fold cv\n",
        "\n",
        "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs=-1)\n",
        "\n",
        "    # Fit on data\n",
        "    best_clf = clf.fit(X, y)\n",
        "\n",
        "    best_hyperparams = best_clf.best_estimator_.get_params()['classifier']\n",
        "\n",
        "    return name, best_hyperparams \n",
        "\n",
        "  if name == 'RF': \n",
        "    param_grid = {'classifier__criterion' : np.array(['gini', 'entropy']),\n",
        "                  'classifier__max_depth' : np.arange(5,11)} \n",
        "    # Create grid search object\n",
        "    # this uses k-fold cv\n",
        "\n",
        "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs=-1)\n",
        "\n",
        "    # Fit on data\n",
        "    best_clf = clf.fit(X, y)\n",
        "\n",
        "    best_hyperparams = best_clf.best_estimator_.get_params()['classifier']\n",
        " \n",
        "    return name, best_hyperparams  \n",
        "\n",
        "  if name == 'XGB':\n",
        "    param_grid = {'classifier__learning_rate' : np.arange(0.022,0.04,.01),\n",
        "                  'classifier__max_depth' : np.arange(5,10)} \n",
        "    # Create grid search object\n",
        "    # this uses k-fold cv\n",
        "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5,  n_jobs=-1)\n",
        "\n",
        "    # Fit on data\n",
        "    best_clf = clf.fit(X, y)\n",
        "    best_hyperparams = best_clf.best_estimator_.get_params()['classifier']\n",
        "\n",
        "    return name, best_hyperparams  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ay2mPQo39mV",
        "colab_type": "text"
      },
      "source": [
        "## Adding Random Forest and XGBoost to our get_stacking() custom function in layer 1 (and removing the poorest performers DT and KNN):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ow6Aqaz27GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_stacking():  \n",
        "def :\n",
        "\n",
        "\t# Create an empty list for the base models called layer1\n",
        "  \n",
        "\n",
        "  # Append tuple with classifier name and instantiations (no arguments) for SVC and GaussianNB base models AND call cust fx #4 best_model on each\n",
        "  # Hint: layer1.append((best_model('ModelName', Classifier())))\n",
        "  \n",
        "\n",
        "  # Add RandomForestClassifier and xgb.XGBClassifier as base models\n",
        "  \n",
        "\n",
        "  # Instantiate Logistic Regression as meta learner model called layer2\n",
        "  \n",
        "\n",
        "\t# Define StackingClassifier() called model passing layer1 model list and meta learner with 5 cross-validations\n",
        "  model = StackingClassifier(estimators=, final_estimator=, cv=)\n",
        "\n",
        "  # return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbp5PICC4HEk",
        "colab_type": "text"
      },
      "source": [
        "## Adding Random Forest and XGBoost to our get_models() custom function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQqQUH_P3Bto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_models():\n",
        "def :\n",
        "\n",
        "  # Create empty dictionary called models\n",
        "  \n",
        "\n",
        "  # Add key:value pairs to dictionary with key as ModelName and value as instantiations (no arguments) for SVC and GaussianNB base models\n",
        "  # Hint: models['ModelName'] = Classifier() \n",
        "  \n",
        "\n",
        "  # we'll add two more classifers to the mix - RandomForestClassifier and xgb.XGBClassifier\n",
        " \n",
        "\n",
        "\n",
        "  # Add key:value pair to dictionary with key called Stacking and value that calls get_stacking() custom function\n",
        "  \n",
        "\n",
        "  # return dictionary\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVTYjSno3B3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign get_models() to a variable called models\n",
        "models = get_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNECWtJ74tZh",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 3: evaluate_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsTJZKNk3XWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define evaluate_model(model):\n",
        "def :\n",
        "\n",
        "  # Create RepeatedStratifiedKFold cross-validator with 10 folds, 3 repeats and a seed of 1.\n",
        "  cv = \n",
        "\n",
        "  # Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'accuracy' scoring, cross validator 'cv', n_jobs=-1, and error_score set to 'raise'\n",
        "  scores = \n",
        "\n",
        "  # return scores\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CxRVSe_DGlI",
        "colab_type": "text"
      },
      "source": [
        "# 10 minute break while the following runs..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXrusVVBAbaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the models and store results\n",
        "# Create an empty list for the results\n",
        "\n",
        "\n",
        "# Create an empty list for the model names\n",
        "\n",
        "\n",
        "# Create a for loop that iterates over each name, model in models dictionary \n",
        "for :\n",
        "\n",
        "\t# Call evaluate_model(model) and assign it to variable called scores\n",
        "\t\n",
        " \n",
        "  # Append output from scores to the results list\n",
        "\t\n",
        " \n",
        "  # Append name to the names list\n",
        "\t\n",
        " \n",
        "  # Print name, mean and standard deviation of scores:\n",
        "\tprint('>%s %.3f (%.3f)' % (, mean(), std()))\n",
        "\n",
        "# Plot model performance for comparison using names for x and results for y and setting showmeans to True\n",
        "sns.boxplot(x=, y=, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZlAHPaD419_",
        "colab_type": "text"
      },
      "source": [
        "## **Observation**\n",
        "- Before we added XGBoost and hyperparameter tuning, our Stacking Classifier got ~ 76% accuracy. \n",
        "- Here, we got just around 77% accuracy, a minor improvement, but an improvement nonetheless.\n",
        "- We could continue fiddling with other algorithms in layer 1\n",
        "- We could try other algorithms in layer 2.\n",
        "- We could add more hyperparameters to our parameter grid.\n",
        "- To this last point, keep in mind that the more parameters there are in a grid to search over, the longer it takes to train the Stacking Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj8WeJR__bUo",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Q&A\n",
        "\n",
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPY3I2BlVxig",
        "colab_type": "text"
      },
      "source": [
        "# **Stacking Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftxDhyDq2lrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.svm import SVR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqDHD8A_nhPB",
        "colab_type": "text"
      },
      "source": [
        "## **2nd Dataset**\n",
        "\n",
        "\n",
        "The second dataset we'll use is a CSV file named `abalone.csv`, which contains data on physical measurements of abalone shells used to determine the age of the abalone.  It contains the following columns:\n",
        "\n",
        "- `Sex`: M, F, and I (infant) - (removed for our purposes)\n",
        "- `Length`: Longest shell measurement (mm)\n",
        "- `Diameter`: Perpendicular to length (mm)\n",
        "- `Height`: with meat in shell (mm)\n",
        "- `Whole weight`: whole abalone (grams)\n",
        "- `Shucked weight`: weight of meat (grams)\n",
        "- `Viscera weight`: gut weight (grams)\n",
        "- `Shell weight`: after being dried (grams)\n",
        "- `Rings`: +1.5 gives the age in years\n",
        "\n",
        "\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwNnn3ZKrh1o",
        "colab_type": "text"
      },
      "source": [
        "### **Get the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4LeaM4PzyAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the dataset as Pandas DataFrame\n",
        "abalone = pd.read_csv('https://github.com/datacamp/Applied-Machine-Learning-Ensemble-Modeling-live-training/blob/master/data/abalone.csv?raw=true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfsmhIBdApVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at data using the info() function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZAeIFGwBhe6",
        "colab_type": "text"
      },
      "source": [
        "## **Observations:** \n",
        "- Here, there are no missing values.  Again, that is not typical.\n",
        "- There is a mixture of object, float, and integers with the first column being `object` (categorical), the next 7 `float64` and the last 'int64`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D4Gfh08Avb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at data using the describe() function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDGc7PPBBkGX",
        "colab_type": "text"
      },
      "source": [
        "## **Observations:** \n",
        "- Notice that the min of the `Height` column is zero.  Even though there are no missing values, this is indicative of the measurements for that feature having not been captured.\n",
        "- Again, the printout makes it appear as if all numeric values are float.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVGtuWoDAvl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the first 5 rows of the data using the head() function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnmVoSl8BmMY",
        "colab_type": "text"
      },
      "source": [
        "## **Observation:**\n",
        "- Printing out the first 5 rows, we see that the 1st column is the only non-numeric feature in this dataset and is aligned with the `object` datatype as we saw above when we called `.info()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfVhWzRrm_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert Pandas DataFrame to numpy array - Return only the values of the DataFrame with DataFrame.to_numpy()\n",
        "abalone = \n",
        "\n",
        "# Create X matrix and y (target) array using slicing [row_start:row_end, 1:target_col],[row_start:row_end, target_col] - Removing 1st column by starting at index 1\n",
        "X, y = \n",
        "\n",
        "# Print X matrix and y (target) array dimensions using .shape\n",
        "print('Shape: %s, %s' % ())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ6CHfsVrpE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert y (target) array to 'float32' using .astype()\n",
        "y = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bYvtBfSF7k7",
        "colab_type": "text"
      },
      "source": [
        "## **Creating a Naive Regressor**\n",
        "Here we'll use the `DummyRegressor` from `sklearn`.  This creates a so-called 'naive' regressor and is simply a model that predicts a single value for all of the rows, regardless of their original value.  \n",
        "\n",
        "1. `DummyRegressor()` arguments:\n",
        " - `strategy`: Strategy to use to generate predictions.\n",
        "\n",
        "2. `RepeatedKFold()` arguments:\n",
        " - `n_splits`: Number of folds.\n",
        " - `n_repeats`: Number of times cross-validator needs to be repeated.\n",
        " - `random_state`: Controls the generation of the random states for each repetition. Pass an int for reproducible output across multiple function calls.  (This is an equivalent argument to np.random.seed above, but will be specific to this naive model.)\n",
        "\n",
        "3. `cross_val_score()` arguments:\n",
        " - The model to use.\n",
        " - The data to fit. (X)\n",
        " - The target variable to try to predict. (y)\n",
        " - `scoring`: A single string scorer callable object/function such as 'accuracy' or 'roc_auc'.  See https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter for more options.\n",
        " - `cv`: Cross-validation splitting strategy (default is 5)\n",
        " - `n_jobs`: Number of CPU cores used when parallelizing.  Set to -1 helps to avoid non-convergence errors.\n",
        " - `error_score`: Value to assign to the score if an error occurs in estimator fitting. If set to â€˜raiseâ€™, the error is raised. If a numeric value is given, FitFailedWarning is raised."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAJdcu_Hrrg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate naive\n",
        "\n",
        "# Instantiate a DummyRegressor with 'median' strategy\n",
        "naive = D\n",
        "\n",
        "# Create RepeatedKFold cross-validator with 10 folds, 3 repeats and a seed of 1.\n",
        "cv = \n",
        "\n",
        "# Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'neg_mean_absolute_error' scoring, cross validator, n_jobs=-1, and error_score set to 'raise'\n",
        "n_scores = \n",
        "\n",
        "# Print mean and standard deviation of n_scores:\n",
        "print('Baseline: %.3f (%.3f)' % (mean(), std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlYQmsCQHcdJ",
        "colab_type": "text"
      },
      "source": [
        "## **Observation** \n",
        "- We want to do better than -2.37 to consider any other models as an improvement to a totally naive regressor model with the Abalone dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfiEdoUMHo-q",
        "colab_type": "text"
      },
      "source": [
        "## **Creating a Baseline Regressor**\n",
        "Now we'll create a baseline regressor, one that seeks to correctly predict the value for each observation.  Since the target variable is continuous, we'll instantiate a Support Vector Regression model.\n",
        "\n",
        "1. `SVR()` arguments:\n",
        " - `kernel`: Specifies the kernel type to be used in the algorithm.\n",
        " - `gamma`:  Kernel coefficient for â€˜rbfâ€™, â€˜polyâ€™ and â€˜sigmoidâ€™. \n",
        " - `C`: Regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFip40FPrvOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate baseline model\n",
        "\n",
        "# Instantiate a Support Vector Regressor with 'rbf' kernel, gamma set to 'scale', and regularization parameter set to 10\n",
        "model = \n",
        "\n",
        "# Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'neg_mean_absolute_error' scoring, cross validator 'cv', n_jobs=-1, and error_score set to 'raise'\n",
        "m_scores = \n",
        "\n",
        "# Print mean and standard deviation of m_scores: \n",
        "print('Good: %.3f (%.3f)' % (mean(), std()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_PMtVARKzBX",
        "colab_type": "text"
      },
      "source": [
        "## **Observation**\n",
        "- We want to do better than -1.48 with a Stacking Regressor to consider it an improvement over this baseline support vector regression model with the Abalone dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-OGF_7bupzn",
        "colab_type": "text"
      },
      "source": [
        "## **Getting started with Stacking Regressor**\n",
        "- We're going to compare several additional baseline regressors to see if they perform better than SVR we just trained previously.\n",
        "- We'll start by importing additional packages that we'll need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxbxTPkPrkNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compare machine learning models for regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import StackingRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yixxr2JLN9UP",
        "colab_type": "text"
      },
      "source": [
        "## Create custom functions\n",
        "1. get_stacking() - This function will create the layers of our `StackingRegressor()`.\n",
        "2. get_models() - This function will create a dictionary of models to be evaluated.\n",
        "3. evaluate_model() - This function will evaluate each of the models to be compared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdF239ZRN92B",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 1: get_stacking()\n",
        "1. `StackingRegressor()` arguments:\n",
        " - `estimators`: List of baseline regressors\n",
        " - `final_estimator`: Defined meta regressor \n",
        " - `cv`: Number of cross validations to perform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoRNxZSj72bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_stacking():\n",
        "def :\n",
        "\n",
        "\t# Create an empty list for the base models called layer1\n",
        "  \n",
        "\n",
        "  # Append tuple with classifier name and instantiations (no arguments) for KNeighborsRegressor, DecisionTreeRegressor, and SVR base models\n",
        "  # Hint: layer1.append(('ModelName', Classifier()))\n",
        "  \n",
        "\n",
        "  # Instantiate Linear Regression as meta learner model called layer2\n",
        "  \n",
        "\n",
        "\t# Define Stackingregressor() called model passing layer1 model list and meta learner with 5 cross-validations\n",
        "  \n",
        "\n",
        "  # return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KClsJExROLAZ",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 2: get_models()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtYbhE_ps4yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_models():\n",
        "def :\n",
        "\n",
        "  # Create empty dictionary called models\n",
        "  \n",
        "\n",
        "  # Add key:value pairs to dictionary with key as ModelName and value as instantiations (no arguments) for KNeighborsRegressor, DecisionTreeRegressor, and SVR base models\n",
        "  # Hint: models['ModelName'] = Classifier()\n",
        "  \n",
        "\n",
        "  # Add key:value pair to dictionary with key called Stacking and value that calls get_stacking() custom function\n",
        "  \n",
        "\n",
        "  # return dictionary\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYH3KcjcOc56",
        "colab_type": "text"
      },
      "source": [
        "## Custom function # 3: evaluate_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H95M82gks6EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define evaluate_model:\n",
        "def :\n",
        "\n",
        "  # Create RepeatedKFold cross-validator with 10 folds, 3 repeats and a seed of 1.\n",
        "\tcv = \n",
        " \n",
        "  # Calculate accuracy using `cross_val_score()` with model instantiated, data to fit, target variable, 'neg_mean_absolute_error' scoring, cross validator 'cv', n_jobs=-1, and error_score set to 'raise'\n",
        "\tscores = \n",
        " \n",
        "  # return scores\n",
        "\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C6Hw-wj56eK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign get_models() to a variable called models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZl3DjmU58Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the models and store results\n",
        "# Create an empty list for the results\n",
        "\n",
        "\n",
        "# Create an empty list for the model names\n",
        "\n",
        "\n",
        "# Create a for loop that iterates over each name, model in models dictionary \n",
        "for :\n",
        "\n",
        "\t# Call evaluate_model(model) and assign it to variable called scores\n",
        "\t\n",
        " \n",
        "  # Append output from scores to the results list\n",
        "\t\n",
        " \n",
        "  # Append name to the names list\n",
        "\t\n",
        " \n",
        "  # Print name, mean and standard deviation of scores:\n",
        "\tprint('>%s %.3f (%.3f)' % (, (), ()))\n",
        " \n",
        "# Plot model performance for comparison using names for x and results for y and setting showmeans to True\n",
        "sns.boxplot(x=, y=, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6EKNBV1UOuG",
        "colab_type": "text"
      },
      "source": [
        "## **Observation**\n",
        "- Recall that we want to do better than -1.48  with a Stacking Regressor to consider it an improvement over this baseline SVR and, although close, we did not achieve that with this dataset.\n",
        "- So what else can try to improve our results with stacking?\n",
        "\n",
        "### We'll add another layer to the mix..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9DZ7iyZFxXo",
        "colab_type": "text"
      },
      "source": [
        "## **Double Stacking - 2 Layers**\n",
        "- Can get a little tricky\n",
        "- Just make sure that you name your layers VERY CLEARLY!\n",
        "- Both the last layer (here it's layer 3) and the stacking model will use a call to `StackingRegressor()`\n",
        "- The last layer will combine the 2nd layer with the final estimator while the model will combine the 1st layer with this last layer.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://github.com/datacamp/Applied-Machine-Learning-Ensemble-Modeling-live-training/blob/master/assets/DoubleStacking.png?raw=True\" alt = \"Double Stacking\" width=\"90%\">\n",
        "</p>\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvUmmQQF6vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define get_stacking() - adding another layer:\n",
        "def :\n",
        "\n",
        "\t# Create an empty list for the 1st layer of base models called layer1\n",
        "  \n",
        "\n",
        "  # Create an empty list for the 2nd layer of base models called layer2\n",
        "  \n",
        "\n",
        "  # Append tuple with classifier name and instantiations (no arguments) for KNeighborsRegressor, DecisionTreeRegressor, and SVR base models\n",
        "  # Hint: layer1.append(('ModelName', Classifier()))\n",
        "  \n",
        "\n",
        "  # Append tuple with classifier name and instantiations (no arguments) for KNeighborsRegressor, DecisionTreeRegressor, and SVR base models\n",
        "  # Hint: layer2.append(('ModelName', Classifier()))\n",
        "  \n",
        "\n",
        "\t# Define meta learner StackingRegressor() called layer3 passing layer2 model list to estimators, LinearRegression() to final_estimator with 5 cross-validations\n",
        "  layer3 = \n",
        "\n",
        "\t# Define StackingRegressor() called model passing layer1 model list to estimators and meta learner (layer3) to final_estimator with 5 cross-validations\n",
        "  model = \n",
        "\n",
        "  # return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnMMqOJ16Bft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign get_models() to a variable called models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvzSjLOEIKUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the models and store results\n",
        "# Create an empty list for the results\n",
        "\n",
        "\n",
        "# Create an empty list for the model names\n",
        "\n",
        "\n",
        "# Create a for loop that iterates over each name, model in models dictionary \n",
        "for ):\n",
        "\n",
        "\t# Call evaluate_model(model) and assign it to variable called scores\n",
        "\t\n",
        " \n",
        "  # Append output from scores to the results list\n",
        "\t\n",
        " \n",
        "  # Append name to the names list\n",
        "\t\n",
        " \n",
        "  # Print name, mean and standard deviation of scores:\n",
        "\tprint('>%s %.3f (%.3f)' % (, (), ()))\n",
        " \n",
        "# Plot model performance for comparison using names for x and results for y and setting showmeans to True\n",
        "sns.( , , )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMgN44SwcJPG",
        "colab_type": "text"
      },
      "source": [
        "## **Final Observation**\n",
        "- Adding a layer did not improve results.\n",
        "- Complexity does not always make a better model\n",
        "- Could try different base models to stack for both of the datasets and that may show improvements over baseline.\n",
        "- Generate polynomial features \n",
        "- Try sklearn feature selection\n",
        "- Try feature engineering - creating new features from existing ones (but remember to remove the original features to avoid multicollinearity)\n",
        "- Tune hyperparameters for grid search as previously with Stacking Classifier\n",
        "- When there is a tie between a baseline model and a stacked model, choose the simpler model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4iX02EkDujS",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# Q&A\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNWB_J4QD0Ad",
        "colab_type": "text"
      },
      "source": [
        "# Back to the slides for wrap-up..."
      ]
    }
  ]
}